{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development: Fine-Tuning Pre-Trained Models\n",
    "Load a previously trained model, freeze most of its layers, and then train it on data from a different city.\n",
    "  \n",
    "Date: 2018-12-06  \n",
    "Author: Peter Kerins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "(may be over-inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'name': u'Illinois', u'id': 85688697, u'placetype': u'region', u'bbox': [-91.512974, 36.970298, -87.019935, 42.508302], u'path': u'continent:north-america_country:united-states_region:illinois', u'slug': u'north-america_united-states_illinois'}]\n",
      "['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/Taufiq.Rashid/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages/PILcompat', '/usr/lib/python2.7/dist-packages/gtk-2.0', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/home/Taufiq.Rashid/.ipython', '/home/Peter.Kerins/UrbanLandUse/utils']\n"
     ]
    }
   ],
   "source": [
    "# typical, comprehensive imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "#\n",
    "import numpy as np\n",
    "import shapely\n",
    "import cartopy\n",
    "import geojson\n",
    "import fiona\n",
    "import gdal\n",
    "import h5py\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import ogr, gdal\n",
    "from keras.models import load_model\n",
    "import math\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from skimage import measure\n",
    "from skimage import filters\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Add, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "\n",
    "import collections\n",
    "\n",
    "import descarteslabs as dl\n",
    "print dl.places.find('illinois') ## TEST\n",
    "\n",
    "#ULU_REPO = os.environ[\"ULU_REPO\"]\n",
    "#sys.path.append(ULU_REPO+'/utils')\n",
    "sys.path.append('/home/Peter.Kerins/UrbanLandUse/utils')\n",
    "print sys.path\n",
    "\n",
    "import util_descartes\n",
    "import util_ml\n",
    "import util_rasters\n",
    "import util_vectors\n",
    "import util_workflow\n",
    "import util_keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root='/data/phase_iii/'\n",
    "#data_path=data_root+place+'/'\n",
    "\n",
    "bands=['blue','green','red','nir','swir1','swir2','alpha']; suffix='BGRNS1S2A'  # S2, Lx\n",
    "resolution=5  # Lx:15 S2:10\n",
    "\n",
    "s1_bands=['vv','vh']; s1_suffix='VVVH'\n",
    "s1_resolution = resolution\n",
    "\n",
    "ndvi_bands = ['raw'];\n",
    "#ndvi_bands = ['raw','min','max'];\n",
    "# ndbi_bands = ['raw','min','max'];\n",
    "\n",
    "tile_resolution = resolution\n",
    "tile_size = 256\n",
    "tile_pad = 16\n",
    "\n",
    "# ground truth source: aue, aue+osm, aue+osm2\n",
    "label_suffix = 'aue'\n",
    "\n",
    "# NYU AoUE land use/land cover categories\n",
    "category_label = {0:'Open Space',1:'Non-Residential',\\\n",
    "                   2:'Residential Atomistic',3:'Residential Informal Subdivision',\\\n",
    "                   4:'Residential Formal Subdivision',5:'Residential Housing Project',\\\n",
    "                   6:'Roads',7:'Study Area',8:'Labeled Study Area',254:'No Data',255:'No Label'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify training data & training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 17\n",
    "\n",
    "cats_map = {}\n",
    "cats_map[0] = 0\n",
    "cats_map[1] = 1\n",
    "cats_map[2] = 4\n",
    "cats_map[3] = 4\n",
    "cats_map[4] = 4\n",
    "cats_map[5] = 4\n",
    "cats_map[6] = 6\n",
    "\n",
    "bands_vir=bands[:-1]\n",
    "bands_sar=None#s1_bands\n",
    "bands_ndvi=ndvi_bands#None\n",
    "bands_ndbi=None\n",
    "bands_osm=None\n",
    "\n",
    "haze_removal = False\n",
    "\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "balancing = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vir+ndvi 7\n"
     ]
    }
   ],
   "source": [
    "stack_label, feature_count = util_workflow.build_stack_label(\n",
    "        bands_vir=bands_vir,\n",
    "        bands_sar=bands_sar,\n",
    "        bands_ndvi=bands_ndvi,\n",
    "        bands_ndbi=bands_ndbi,\n",
    "        bands_osm=bands_osm,)\n",
    "print stack_label, feature_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training data \"superset\"\n",
    "The \"superset\" of training data used to actually train a model can be a combination of any number of stored training data sets built from particular input stacks. These constituent sets can come from one or many cities. The only requirement is that they are all consistent in construction, ie are built from the same input stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate total size of training and validation supersets\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_Q.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_Q.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_R.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_R.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_T.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_T.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_U.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_U.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_V.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_V.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "603925 258830\n",
      "construct np arrays for supersets\n",
      "populate superset np arrays\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_Q.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_Q.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_R.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_R.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_T.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_T.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_U.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_U.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "/data/phase_iii/sitapur/sitapur_train_aue_5m_vir+ndvi_17w_V.pkl\n",
      "/data/phase_iii/sitapur/sitapur_valid_aue_5m_vir+ndvi_17w_V.pkl\n",
      "(120785, 2023) (120785,) (51766, 2023) (51766,)\n",
      "(603925, 2023) (603925,)\n"
     ]
    }
   ],
   "source": [
    "reload(util_workflow)\n",
    "place_images = {}\n",
    "\n",
    "place_images['sitapur'] = ['Q','R','T','U','V']\n",
    "\n",
    "X_train_raw, Y_train_raw, X_valid_raw, Y_valid_raw = util_workflow.load_datasets(place_images, data_root, label_suffix, stack_label, window, resolution=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603925, 2023) (258830, 2023)\n",
      "(603925, 2023) (258830, 2023)\n"
     ]
    }
   ],
   "source": [
    "X_train_raw_scaled, X_valid_raw_scaled, scaler = util_ml.scale_learning_data(X_train_raw, X_valid_raw)\n",
    "print X_train_raw_scaled.shape,  X_valid_raw_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_raw, X_valid_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_raw_scaled.reshape((X_train_raw_scaled.shape[0],feature_count,window,window))\n",
    "X_valid = X_valid_raw_scaled.reshape((X_valid_raw_scaled.shape[0],feature_count,window,window))\n",
    "#print(X_train_raw[0])\n",
    "#print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_raw_scaled, X_valid_raw_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603925, 7, 17, 17)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training data for ingestion\n",
    "This version of the workflow does not include class-balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remap original set of categories (from the Atlas of Urban Expansion) encoded in the ground-truth files and the training data files to a target typology (eg collapsing all residential LULC types to a single category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train_raw.copy()\n",
    "Y_valid = Y_valid_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603925,)\n",
      "(603925,)\n"
     ]
    }
   ],
   "source": [
    "for k, v in cats_map.items():\n",
    "    Y_train[Y_train_raw==k] = v\n",
    "    Y_valid[Y_valid_raw==k] = v\n",
    "    \n",
    "print Y_train_raw.shape\n",
    "print Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Y_train_raw, Y_valid_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_roads = np.where(Y_train!=6)\n",
    "Y_train = Y_train[non_roads]\n",
    "X_train = X_train[non_roads]\n",
    "non_roads = np.where(Y_valid!=6)\n",
    "Y_valid = Y_valid[non_roads]\n",
    "X_valid = X_valid[non_roads]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reduce the remapped values to the categorical values required by the Keras library. These pre-processing steps could be consolidated, but represent two separate conceptual parts of the workflow, so are executed separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_t = Y_train.copy()\n",
    "Y_v = Y_valid.copy()\n",
    "\n",
    "Y_t[Y_train==0] = 0\n",
    "Y_t[Y_train==1] = 1\n",
    "Y_t[Y_train==4] = 2\n",
    "Y_t[Y_train==6] = 3\n",
    "\n",
    "Y_v[Y_valid==0] = 0\n",
    "Y_v[Y_valid==1] = 1\n",
    "Y_v[Y_valid==4] = 2\n",
    "Y_v[Y_valid==6] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Y data to one-hot structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_reduced = [0,1,2]\n",
    "\n",
    "Y_t_cat = to_categorical(Y_t)\n",
    "Y_v_cat = to_categorical(Y_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541725,)\n",
      "(541725, 3)\n"
     ]
    }
   ],
   "source": [
    "print Y_t.shape\n",
    "print Y_t_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Keras variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DEFAULT:', 'channels_last')\n",
      "('UPDATED:', 'channels_first')\n"
     ]
    }
   ],
   "source": [
    "print(\"DEFAULT:\",K.image_data_format())\n",
    "K.set_image_data_format('channels_first')\n",
    "print(\"UPDATED:\",K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_FILTERS_1=32\n",
    "NB_FILTERS_2=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_id = '3cat_Hin_U-AB'\n",
    "weights_label='WCC_weights.best'\n",
    "filepath = data_root+'models/'+original_model_id+'_'+weights_label+'.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 7, 17, 17)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 17, 17)   5632        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 17, 17)   2048        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 17, 17)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 17, 17)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 17, 17)   25632       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 17, 17)   9248        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 17, 17)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 17, 17)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 17, 17)   256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 32, 17, 17)   0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 32, 17, 17)   0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 32, 17, 17)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 17, 17)   0           lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 8, 8)     0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 8, 8)     0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 8, 8)     51264       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 8, 8)     18496       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 64, 8, 8)     0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 64, 8, 8)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 8, 8)     102464      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 8, 8)     36928       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 64, 8, 8)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 64, 8, 8)     0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 8, 8)     2112        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 64, 8, 8)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 64, 8, 8)     0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 64, 8, 8)     0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 8, 8)     0           lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 64, 4, 4)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 4, 4)     0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1024)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          524800      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 512)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            1539        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3)            0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 780,419\n",
      "Trainable params: 780,419\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild network\n",
    "network=util_keras.build_model(util_keras.doubleres_block,input_shape=X_train.shape[-3:],output_nodes=len(categories_reduced))\n",
    "# load weights from fast learning\n",
    "network.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables and prepare objects for new, fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '3cat_Sit_QRTUV_tuned'\n",
    "notes = 'test of fine-tuning. sitapur QRTUV based on trained hindupur model \\'3cat_Hin_U-AB\\'.3-category; 5m bilinear with plain aue, green images from 2017 for Sitapur'\n",
    "weights_label='WCC_weights_tuned.best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights [1.0, 2.7794092921593903, 1.2122760272800606]\n"
     ]
    }
   ],
   "source": [
    "# weights and loss\n",
    "weights = util_ml.generate_category_weights(place_images,category_label,label_suffix,stack_label,window,data_root,use_log=True,\n",
    "                                   columns=['image_name','Open Space','Non-Residential','Residential-Total'],resolution=resolution)\n",
    "print 'weights', weights\n",
    "loss = util_keras.weighted_categorical_crossentropy(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare network and training objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks, history_path = util_keras.create_callbacks(data_root, model_id, weights_label=weights_label, patience=3)\n",
    "util_keras.compile_network(network, loss, LR=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Option 1\": training classifier from scratch\n",
    "Not included here, as there is a separate notebook for that (should be titled something like \"core_train-model-3category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Option 2\": starting with pre-trained weights but training all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 541725 samples, validate on 232420 samples\n",
      "Epoch 1/500\n",
      "541725/541725 [==============================] - 142s 262us/step - loss: 0.9707 - acc: 0.7170 - val_loss: 0.7584 - val_acc: 0.7735\n",
      "Epoch 2/500\n",
      "541725/541725 [==============================] - 139s 257us/step - loss: 0.7354 - acc: 0.7816 - val_loss: 0.6249 - val_acc: 0.8149\n",
      "Epoch 3/500\n",
      "334976/541725 [=================>............] - ETA: 47s - loss: 0.6481 - acc: 0.8087"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-68391a7765c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'# train slow\\nhistory_tuned = network.fit(X_train, Y_t_cat, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, Y_v_cat),\\n          shuffle=True,callbacks=callbacks)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train slow\n",
    "history_tuned = network.fit(X_train, Y_t_cat, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, Y_v_cat),shuffle=True,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_slow.history['val_acc'])\n",
    "plt.show()\n",
    "plt.plot(history_slow.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"evaluate training\"\n",
    "Yhat_t_prob = network.predict(X_train)\n",
    "Yhat_t = Yhat_t_prob.argmax(axis=-1)\n",
    "train_confusion = util_ml.calc_confusion(Yhat_t,Y_t,categories_reduced)\n",
    "train_recalls, train_precisions, train_accuracy = util_ml.calc_confusion_details(train_confusion)\n",
    "\n",
    "# Calculate f-score\n",
    "beta = 2\n",
    "train_f_score = (beta**2 + 1) * train_precisions * train_recalls / ( (beta**2 * train_precisions) + train_recalls )\n",
    "train_f_score_open = train_f_score[0] \n",
    "train_f_score_nonres = train_f_score[1]  \n",
    "train_f_score_res = train_f_score[2]  \n",
    "train_f_score_roads = None#train_f_score[3]  \n",
    "train_f_score_average = np.mean(train_f_score)\n",
    "\n",
    "print \"evaluate validation\"\n",
    "Yhat_v_prob = network.predict(X_valid)\n",
    "Yhat_v = Yhat_v_prob.argmax(axis=-1)\n",
    "valid_confusion = util_ml.calc_confusion(Yhat_v,Y_v,categories_reduced)\n",
    "valid_recalls, valid_precisions, valid_accuracy = util_ml.calc_confusion_details(valid_confusion)\n",
    "\n",
    "# Calculate f-score\n",
    "valid_f_score = (beta**2 + 1) * valid_precisions * valid_recalls / ( (beta**2 * valid_precisions) + valid_recalls )\n",
    "valid_f_score_open = valid_f_score[0] \n",
    "valid_f_score_nonres = valid_f_score[1] \n",
    "valid_f_score_res = valid_f_score[2] \n",
    "valid_f_score_roads = None# valid_f_score[3] \n",
    "valid_f_score_average = np.mean(valid_f_score)\n",
    "\n",
    "# expanding lists to match expected model_record stuff\n",
    "train_recalls_expanded = [train_recalls[0],train_recalls[1],train_recalls[2],None]\n",
    "valid_recalls_expanded = [valid_recalls[0],valid_recalls[1],valid_recalls[2],None]\n",
    "train_precisions_expanded = [train_precisions[0],train_precisions[1],train_precisions[2],None]\n",
    "valid_precisions_expanded = [valid_precisions[0],valid_precisions[1],valid_precisions[2],None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End \"Option 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Option 3\": freeze all but final (flattened) layers and train only those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<keras.engine.topology.InputLayer object at 0x7f5047419a50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f52221bcf10>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f50473e96d0>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f5047435ed0>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f5047380b90>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f5047435c50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f50903809d0>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f5047435650>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f5090380850>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f50474bb990>, False)\n",
      "(<keras.layers.core.Lambda object at 0x7f50473847d0>, False)\n",
      "(<keras.layers.core.Lambda object at 0x7f504736f110>, False)\n",
      "(<keras.layers.core.Lambda object at 0x7f504736f8d0>, False)\n",
      "(<keras.layers.merge.Add object at 0x7f504736f150>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7f50903c98d0>, False)\n",
      "(<keras.layers.core.Dropout object at 0x7f5047343d50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f50472d1090>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f50472b0190>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f50472d1b10>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f50472b0950>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f50472f6bd0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f504725b110>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f504728b3d0>, False)\n",
      "(<keras.layers.core.Activation object at 0x7f504725b8d0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7f5047270990>, False)\n",
      "(<keras.layers.core.Lambda object at 0x7f5047205850>, False)\n",
      "(<keras.layers.core.Lambda object at 0x7f5047219910>, False)\n",
      "(<keras.layers.core.Lambda object at 0x7f50472307d0>, False)\n",
      "(<keras.layers.merge.Add object at 0x7f5047230090>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7f50471d8fd0>, False)\n",
      "(<keras.layers.core.Dropout object at 0x7f50471c5890>, False)\n",
      "(<keras.layers.core.Flatten object at 0x7f50471efa10>, False)\n",
      "(<keras.layers.core.Dense object at 0x7f50471ef650>, True)\n",
      "(<keras.layers.core.Activation object at 0x7f50471aae90>, True)\n",
      "(<keras.layers.core.Dropout object at 0x7f50471aaed0>, True)\n",
      "(<keras.layers.core.Dense object at 0x7f50471aad90>, True)\n",
      "(<keras.layers.core.Activation object at 0x7f5047167d90>, True)\n"
     ]
    }
   ],
   "source": [
    "# freeze relevant layers\n",
    "for layer in network.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in network.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 541725 samples, validate on 232420 samples\n",
      "Epoch 1/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.9697 - acc: 0.7166 - val_loss: 0.7596 - val_acc: 0.7779\n",
      "Epoch 2/500\n",
      "541725/541725 [==============================] - 142s 263us/step - loss: 0.7332 - acc: 0.7829 - val_loss: 0.6194 - val_acc: 0.8167\n",
      "Epoch 3/500\n",
      "541725/541725 [==============================] - 143s 263us/step - loss: 0.6319 - acc: 0.8140 - val_loss: 0.5322 - val_acc: 0.8422\n",
      "Epoch 4/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.5585 - acc: 0.8356 - val_loss: 0.4597 - val_acc: 0.8608\n",
      "Epoch 5/500\n",
      "541725/541725 [==============================] - 145s 269us/step - loss: 0.5037 - acc: 0.8521 - val_loss: 0.4037 - val_acc: 0.8785\n",
      "Epoch 6/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.4576 - acc: 0.8656 - val_loss: 0.3641 - val_acc: 0.8909\n",
      "Epoch 7/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.4201 - acc: 0.8766 - val_loss: 0.3287 - val_acc: 0.8996\n",
      "Epoch 8/500\n",
      "541725/541725 [==============================] - 145s 269us/step - loss: 0.3881 - acc: 0.8861 - val_loss: 0.3034 - val_acc: 0.9059\n",
      "Epoch 9/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.3617 - acc: 0.8939 - val_loss: 0.2784 - val_acc: 0.9151\n",
      "Epoch 10/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.3392 - acc: 0.8997 - val_loss: 0.2632 - val_acc: 0.9178\n",
      "Epoch 11/500\n",
      "541725/541725 [==============================] - 146s 270us/step - loss: 0.3212 - acc: 0.9044 - val_loss: 0.2455 - val_acc: 0.9243\n",
      "Epoch 12/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.3060 - acc: 0.9090 - val_loss: 0.2313 - val_acc: 0.9273\n",
      "Epoch 13/500\n",
      "541725/541725 [==============================] - 146s 270us/step - loss: 0.2898 - acc: 0.9139 - val_loss: 0.2236 - val_acc: 0.9300\n",
      "Epoch 14/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.2760 - acc: 0.9173 - val_loss: 0.2287 - val_acc: 0.9246\n",
      "Epoch 15/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.2653 - acc: 0.9211 - val_loss: 0.2116 - val_acc: 0.9312\n",
      "Epoch 16/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.2542 - acc: 0.9237 - val_loss: 0.2000 - val_acc: 0.9367\n",
      "Epoch 17/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.2465 - acc: 0.9261 - val_loss: 0.1952 - val_acc: 0.9372\n",
      "Epoch 18/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.2389 - acc: 0.9283 - val_loss: 0.1841 - val_acc: 0.9422\n",
      "Epoch 19/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.2311 - acc: 0.9309 - val_loss: 0.1875 - val_acc: 0.9388\n",
      "Epoch 20/500\n",
      "541725/541725 [==============================] - 148s 273us/step - loss: 0.2240 - acc: 0.9329 - val_loss: 0.1744 - val_acc: 0.9443\n",
      "Epoch 21/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.2184 - acc: 0.9341 - val_loss: 0.1781 - val_acc: 0.9425\n",
      "Epoch 22/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.2122 - acc: 0.9361 - val_loss: 0.1637 - val_acc: 0.9479\n",
      "Epoch 23/500\n",
      "541725/541725 [==============================] - 146s 270us/step - loss: 0.2069 - acc: 0.9376 - val_loss: 0.1607 - val_acc: 0.9495\n",
      "Epoch 24/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.2004 - acc: 0.9395 - val_loss: 0.1655 - val_acc: 0.9441\n",
      "Epoch 25/500\n",
      "541725/541725 [==============================] - 145s 269us/step - loss: 0.1964 - acc: 0.9409 - val_loss: 0.1572 - val_acc: 0.9501\n",
      "Epoch 26/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.1913 - acc: 0.9418 - val_loss: 0.1578 - val_acc: 0.9476\n",
      "Epoch 27/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.1878 - acc: 0.9429 - val_loss: 0.1548 - val_acc: 0.9500\n",
      "Epoch 28/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1853 - acc: 0.9441 - val_loss: 0.1515 - val_acc: 0.9504\n",
      "Epoch 29/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1810 - acc: 0.9453 - val_loss: 0.1494 - val_acc: 0.9510\n",
      "Epoch 30/500\n",
      "541725/541725 [==============================] - 144s 265us/step - loss: 0.1782 - acc: 0.9459 - val_loss: 0.1499 - val_acc: 0.9503\n",
      "Epoch 31/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1732 - acc: 0.9473 - val_loss: 0.1430 - val_acc: 0.9542\n",
      "Epoch 32/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1707 - acc: 0.9480 - val_loss: 0.1427 - val_acc: 0.9538\n",
      "Epoch 33/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1683 - acc: 0.9487 - val_loss: 0.1400 - val_acc: 0.9555\n",
      "Epoch 34/500\n",
      "541725/541725 [==============================] - 144s 265us/step - loss: 0.1654 - acc: 0.9499 - val_loss: 0.1464 - val_acc: 0.9522\n",
      "Epoch 35/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1630 - acc: 0.9505 - val_loss: 0.1384 - val_acc: 0.9561\n",
      "Epoch 36/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1609 - acc: 0.9508 - val_loss: 0.1350 - val_acc: 0.9573\n",
      "Epoch 37/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1579 - acc: 0.9521 - val_loss: 0.1405 - val_acc: 0.9547\n",
      "Epoch 38/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.1554 - acc: 0.9527 - val_loss: 0.1367 - val_acc: 0.9560\n",
      "Epoch 39/500\n",
      "541725/541725 [==============================] - 144s 265us/step - loss: 0.1540 - acc: 0.9531 - val_loss: 0.1362 - val_acc: 0.9547\n",
      "Train on 541725 samples, validate on 232420 samples\n",
      "Epoch 1/500\n",
      "541725/541725 [==============================] - 143s 264us/step - loss: 0.1520 - acc: 0.9535 - val_loss: 0.1372 - val_acc: 0.9555\n",
      "Epoch 2/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.1510 - acc: 0.9539 - val_loss: 0.1350 - val_acc: 0.9565\n",
      "Epoch 3/500\n",
      "541725/541725 [==============================] - 146s 269us/step - loss: 0.1486 - acc: 0.9546 - val_loss: 0.1290 - val_acc: 0.9604\n",
      "Epoch 4/500\n",
      "541725/541725 [==============================] - 145s 268us/step - loss: 0.1465 - acc: 0.9555 - val_loss: 0.1292 - val_acc: 0.9584\n",
      "Epoch 5/500\n",
      "541725/541725 [==============================] - 144s 266us/step - loss: 0.1448 - acc: 0.9555 - val_loss: 0.1310 - val_acc: 0.9580\n",
      "Epoch 6/500\n",
      "541725/541725 [==============================] - 143s 264us/step - loss: 0.1433 - acc: 0.9563 - val_loss: 0.1388 - val_acc: 0.9544\n",
      "Train on 541725 samples, validate on 232420 samples\n",
      "Epoch 1/500\n",
      "264832/541725 [=============>................] - ETA: 1:03 - loss: 0.1419 - acc: 0.9566"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-68391a7765c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'# train slow\\nhistory_tuned = network.fit(X_train, Y_t_cat, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, Y_v_cat),\\n          shuffle=True,callbacks=callbacks)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1060\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/timeit.pyc\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train slow\n",
    "history_tuned = network.fit(X_train, Y_t_cat, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, Y_v_cat),shuffle=True,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_tuned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-4e7aac1dfcaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_tuned' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history_tuned.history['val_acc'])\n",
    "plt.show()\n",
    "plt.plot(history_tuned.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate training\n",
      "0 247965\n",
      "1 89215\n",
      "2 204545\n",
      "[[238332   5467   4166]\n",
      " [   136  89049     30]\n",
      " [  1708   1638 201199]]\n",
      "541725 528580 0.9757349208546772\n",
      "evaluate validation\n",
      "0 105720\n",
      "1 38780\n",
      "2 87920\n",
      "[[99676  3339  2705]\n",
      " [  576 37986   218]\n",
      " [ 1599  1216 85105]]\n",
      "232420 222767 0.958467429653214\n"
     ]
    }
   ],
   "source": [
    "print \"evaluate training\"\n",
    "Yhat_t_prob = network.predict(X_train)\n",
    "Yhat_t = Yhat_t_prob.argmax(axis=-1)\n",
    "train_confusion = util_ml.calc_confusion(Yhat_t,Y_t,categories_reduced)\n",
    "train_recalls, train_precisions, train_accuracy = util_ml.calc_confusion_details(train_confusion)\n",
    "\n",
    "# Calculate f-score\n",
    "beta = 2\n",
    "train_f_score = (beta**2 + 1) * train_precisions * train_recalls / ( (beta**2 * train_precisions) + train_recalls )\n",
    "train_f_score_open = train_f_score[0] \n",
    "train_f_score_nonres = train_f_score[1]  \n",
    "train_f_score_res = train_f_score[2]  \n",
    "train_f_score_roads = None#train_f_score[3]  \n",
    "train_f_score_average = np.mean(train_f_score)\n",
    "\n",
    "print \"evaluate validation\"\n",
    "Yhat_v_prob = network.predict(X_valid)\n",
    "Yhat_v = Yhat_v_prob.argmax(axis=-1)\n",
    "valid_confusion = util_ml.calc_confusion(Yhat_v,Y_v,categories_reduced)\n",
    "valid_recalls, valid_precisions, valid_accuracy = util_ml.calc_confusion_details(valid_confusion)\n",
    "\n",
    "# Calculate f-score\n",
    "valid_f_score = (beta**2 + 1) * valid_precisions * valid_recalls / ( (beta**2 * valid_precisions) + valid_recalls )\n",
    "valid_f_score_open = valid_f_score[0] \n",
    "valid_f_score_nonres = valid_f_score[1] \n",
    "valid_f_score_res = valid_f_score[2] \n",
    "valid_f_score_roads = None# valid_f_score[3] \n",
    "valid_f_score_average = np.mean(valid_f_score)\n",
    "\n",
    "# expanding lists to match expected model_record stuff\n",
    "train_recalls_expanded = [train_recalls[0],train_recalls[1],train_recalls[2],None]\n",
    "valid_recalls_expanded = [valid_recalls[0],valid_recalls[1],valid_recalls[2],None]\n",
    "train_precisions_expanded = [train_precisions[0],train_precisions[1],train_precisions[2],None]\n",
    "valid_precisions_expanded = [valid_precisions[0],valid_precisions[1],valid_precisions[2],None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End \"Option 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save objects and record model in scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/phase_iii/models/3cat_Sit_QRTUV_tuned_scaler.pkl\n",
      "/data/phase_iii/models/3cat_Sit_QRTUV_tunedDLv3.hd5\n"
     ]
    }
   ],
   "source": [
    "scaler_filename = data_root+'models/'+model_id+'_scaler.pkl'\n",
    "#model_filename  = data_root+'models/'+model_id+'_SVM.pkl'\n",
    "network_filename = data_root+'models/'+model_id+'DLv3.hd5'\n",
    "\n",
    "if os.path.exists(scaler_filename):\n",
    "    print 'Aborting all pickle operations: file already exists at specified path ('+scaler_filename+')'\n",
    "#elif os.path.exists(model_filename):\n",
    "#    print 'Aborting all pickle operations: file already exists at specified path ('+model_filename+')'\n",
    "elif os.path.exists(network_filename):\n",
    "    print 'Aborting all pickle operations: file already exists at specified path ('+network_filename+')'\n",
    "else:\n",
    "    print scaler_filename\n",
    "#    print model_filename\n",
    "    print network_filename\n",
    "    pickle.dump(scaler, open(scaler_filename, 'wb'))\n",
    "#    pickle.dump(model, open(model_filename, 'wb'))\n",
    "    network.save(network_filename)\n",
    "    # tracking only occurs if all saves are successful\n",
    "    util_workflow.record_model_creation(\n",
    "        model_id, notes, place_images, label_suffix, resolution, stack_label, feature_count, window, cats_map, balancing, \n",
    "        network.get_config(), epochs, batch_size,\n",
    "        train_confusion, train_recalls_expanded, train_precisions_expanded, train_accuracy,\n",
    "        train_f_score_open, train_f_score_nonres, train_f_score_res, train_f_score_roads, train_f_score_average,\n",
    "        valid_confusion, valid_recalls_expanded, valid_precisions_expanded, valid_accuracy,\n",
    "        valid_f_score_open, valid_f_score_nonres, valid_f_score_res, valid_f_score_roads, valid_f_score_average,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
