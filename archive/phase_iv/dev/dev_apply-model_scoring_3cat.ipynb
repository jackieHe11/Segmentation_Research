{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core: Applying 3-Category Classifier for Scoring\n",
    "Apply trained model to samples in catalog in order to assess model performance.  \n",
    "\n",
    "This notebook addresses only scoring, not mapping.\n",
    "  \n",
    "Date: 2019-06-27  \n",
    "Author: Peter Kerins  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "(may be over-inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/Peter.Kerins/anaconda3/envs/geoml/lib/python36.zip', '/home/Peter.Kerins/anaconda3/envs/geoml/lib/python3.6', '/home/Peter.Kerins/anaconda3/envs/geoml/lib/python3.6/lib-dynload', '', '/home/Peter.Kerins/anaconda3/envs/geoml/lib/python3.6/site-packages', '/home/Peter.Kerins/anaconda3/envs/geoml/lib/python3.6/site-packages/IPython/extensions', '/home/Peter.Kerins/.ipython', '/home/Peter.Kerins/UrbanLandUse']\n"
     ]
    }
   ],
   "source": [
    "# typical, comprehensive imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "#\n",
    "import numpy as np\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from tensorflow.keras import models\n",
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# import tensorflow.keras as keras\n",
    "# import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# from tensorflow.keras.layers import Input, Add, Lambda\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "\n",
    "import descarteslabs as dl\n",
    "\n",
    "ULU_REPO = os.environ[\"ULU_REPO\"]\n",
    "if not ULU_REPO in sys.path:\n",
    "    sys.path.append(ULU_REPO)\n",
    "# ulu_utils = ULU_REPO+'/utils'\n",
    "# if not ulu_utils in sys.path:\n",
    "#     sys.path.append(ulu_utils)\n",
    "print (sys.path)\n",
    "\n",
    "import utils.util_chips as util_chips\n",
    "import utils.util_workflow as util_workflow\n",
    "from utils.catalog_generator import CatalogGenerator\n",
    "import utils.util_scoring as util_scoring\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core\n",
    "data_root='/data/phase_iv/'\n",
    "\n",
    "resolution = 5  # Lx:15 S2:10\n",
    "\n",
    "# tiling\n",
    "tile_resolution = resolution\n",
    "tile_size = 256\n",
    "tile_pad = 32\n",
    "\n",
    "look_window = 17\n",
    "batch_size = 128\n",
    "\n",
    "# misc\n",
    "s2_bands=['blue','green','red','nir','swir1','swir2','alpha']; suffix='BGRNS1S2A'  # S2, Lx\n",
    "\n",
    "# ground truth source: aue, aue+osm, aue+osm2\n",
    "label_suffix = 'aue'\n",
    "label_lot = '0'\n",
    "resolution = 5\n",
    "resampling = 'bilinear'\n",
    "processing = None\n",
    "source = 's2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_label = {0:'Open Space',1:'Non-Residential',\\\n",
    "                   2:'Residential Atomistic',3:'Residential Informal Subdivision',\\\n",
    "                   4:'Residential Formal Subdivision',5:'Residential Housing Project',\\\n",
    "                   6:'Roads',7:'Study Area',8:'Labeled Study Area',254:'No Data',255:'No Label'}\n",
    "\n",
    "cats_map = {}\n",
    "cats_map[0] = 0\n",
    "cats_map[1] = 1\n",
    "cats_map[2] = 2\n",
    "cats_map[3] = 2\n",
    "cats_map[4] = 2\n",
    "cats_map[5] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input stack and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window = 17\n",
    "\n",
    "# bands stuff outdated! needs to be reconciled with catalog filtering\n",
    "# will ignore for the moment since this is a bigger fix...\n",
    "# haven't done any examples yet incorporating additional chips beyond s2\n",
    "# into construction of a training sample\n",
    "bands_vir=s2_bands[:-1]\n",
    "bands_sar=None\n",
    "bands_ndvi=None\n",
    "bands_ndbi=None\n",
    "bands_osm=None\n",
    "\n",
    "# this can get updated when cloudmasking is added\n",
    "haze_removal = False\n",
    "\n",
    "batch_size = 128\n",
    "balancing = None\n",
    "\n",
    "# move as appropriate\n",
    "\n",
    "model_id = '3cat_14ct_green_2017_2-img-bl'\n",
    "unflatten_input = True # is the model a cnn?\n",
    "n_cats = 3 # number of categories\n",
    "\n",
    "water_overwrite = False\n",
    "water_mask = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vir 6\n"
     ]
    }
   ],
   "source": [
    "stack_label, feature_count = util_workflow.build_stack_label(\n",
    "        bands_vir=bands_vir,\n",
    "        bands_sar=bands_sar,\n",
    "        bands_ndvi=bands_ndvi,\n",
    "        bands_ndbi=bands_ndbi,\n",
    "        bands_osm=bands_osm,)\n",
    "print(stack_label, feature_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/Peter.Kerins/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/Peter.Kerins/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/Peter.Kerins/anaconda3/envs/geoml/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 17, 17, 6)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 17, 17, 32)   1760        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 17, 17, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 17, 17, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 17, 17, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 17, 17, 32)   1312        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 17, 17, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 17, 17, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 17, 17, 32)   1312        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 17, 17, 32)   128         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 32)     1024        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 9, 9, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 9, 9, 32)     128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 9, 9, 32)     0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 9, 9, 32)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 9, 9, 64)     2336        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 9, 9, 64)     256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 9, 9, 64)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 9, 9, 64)     4672        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 9, 9, 64)     256         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 5, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5, 5, 64)     256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5, 5, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          819712      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            1539        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 3)            0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 846,115\n",
      "Trainable params: 845,539\n",
      "Non-trainable params: 576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# category_weights_filename = data_root+'models/'+model_id+'_category_weights.pkl'\n",
    "# category_weights = pickle.load( open( category_weights_filename, \"rb\" ) )\n",
    "# weights = list(zip(*category_weights.items())[1])\n",
    "\n",
    "network_filename = data_root+'models/'+model_id+'.hd5'\n",
    "network = tf.keras.models.load_model(\n",
    "    network_filename,\n",
    "    custom_objects={'loss': 'categorical_crossentropy'},\n",
    "    compile=True\n",
    ")\n",
    "# network = K.load_model(network_filename, custom_objects={'loss': 'categorical-crossentropy'})\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply model: score results\n",
    "Apply model to some set of chips and compare its predictions to the actual LULC values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify desired images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_images = {}\n",
    "place_images['hindupur']=['U']\n",
    "# place_images['hindupur']=['U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "# place_images['singrauli']=['O','P','Q','R','S','T','U']\n",
    "# place_images['vijayawada']=['H','I']\n",
    "# place_images['jaipur']=['T','U','W','X','Y','Z']\n",
    "# place_images['hyderabad']=['P','Q','R','S','T','U']\n",
    "# place_images['sitapur']=['Q','R','T','U','V']\n",
    "# place_images['kanpur']=['AH', 'AK', 'AL', 'AM', 'AN']\n",
    "# place_images['belgaum']=['P','Q','R','S','T']\n",
    "# place_images['parbhani']=['T','V','W','X','Y','Z']\n",
    "# place_images['pune']=['P', 'Q', 'T', 'U', 'S']\n",
    "# place_images['ahmedabad']= ['Z', 'V', 'W', 'X', 'Y', 'AA']\n",
    "# place_images['malegaon']=  ['V', 'W', 'X', 'Y', 'Z']\n",
    "# place_images['kolkata'] =  ['M','N','O','P','Q','R']\n",
    "# place_images['mumbai']=['P','Q','R','S','U','V']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter catalog to selected chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39281620\n"
     ]
    }
   ],
   "source": [
    "df = util_chips.load_catalog()\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107891\n"
     ]
    }
   ],
   "source": [
    "mask = pd.Series(data=np.zeros(len(df.index),dtype='uint8'), index=range(len(df)), dtype='uint8')\n",
    "\n",
    "for place,image_list in place_images.items():\n",
    "    for image in image_list:\n",
    "        mask |= (df['city']==place) & (df['image']==image)\n",
    "\n",
    "# straight away remove road samples\n",
    "mask &= (df['lulc']!=6)\n",
    "\n",
    "# filter others according to specifications\n",
    "mask &= (df['gt_type']==label_suffix)\n",
    "mask &= (df['gt_lot']==int(label_lot))\n",
    "mask &= (df['source']==source)\n",
    "mask &= (df['resolution']==int(resolution))\n",
    "mask &= (df['resampling']==resampling)\n",
    "mask &= (df['processing']==str(processing).lower())\n",
    "\n",
    "print(np.sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107891"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here for example we will just exclude all roads samples\n",
    "df = df[mask]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate training and validation locales (if desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_locales_paths = [\n",
    "                       '/data/phase_iv/models/3cat_Hin_U-Z_place_locales.pkl'       ,\n",
    "                       ]\n",
    "# place_locales_paths = ['/data/phase_iv/models/3cat_Ahm_V-AA_place_locales.pkl',\n",
    "#                        '/data/phase_iv/models/3cat_Bel_P-T_place_locales.pkl'       ,\n",
    "#                        '/data/phase_iv/models/3cat_Hin_U-Z_place_locales.pkl'       ,\n",
    "#                        '/data/phase_iv/models/3cat_Hyd_P-U_place_locales.pkl'       ,\n",
    "#                        '/data/phase_iv/models/3cat_Jai_T-U+W-Z_place_locales.pkl'   ,\n",
    "#                        '/data/phase_iv/models/3cat_Kan_AH+AK-AN_place_locales.pkl'  ,\n",
    "#                        '/data/phase_iv/models/3cat_Mal_V-Z_place_locales.pkl'       ,\n",
    "#                        '/data/phase_iv/models/3cat_Par_T+V-Z_place_locales.pkl',\n",
    "#                        '/data/phase_iv/models/3cat_Pun_P-Q+S-U_place_locales.pkl',\n",
    "#                        '/data/phase_iv/models/3cat_Sin_O-U_place_locales.pkl',\n",
    "#                        '/data/phase_iv/models/3cat_Sit_Q-R+T-V_place_locales.pkl',\n",
    "#                        '/data/phase_iv/models/3cat_Vij_H-I_place_locales.pkl',\n",
    "#                        '/data/phase_iv/models/3cat_Kol_M-R_place_locales.pkl',\n",
    "#                        '/data/phase_iv/models/3cat_Mum_P-V_place_locales.pkl'\n",
    "#                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hindupur': (array([ 0, 29, 28, 18, 17, 16, 15, 27,  9, 13, 20, 12, 24, 25,  3,  1,  5,\n",
      "       11,  4, 26,  2]), array([ 6, 10,  7, 30,  8, 21, 22, 14, 19, 23]))}\n"
     ]
    }
   ],
   "source": [
    "combined_place_locales = {}\n",
    "for place_locales_filename in place_locales_paths:\n",
    "    with open(place_locales_filename, \"rb\") as f:\n",
    "        place_locales = pickle.load(f,encoding='latin1')\n",
    "    combined_place_locales.update(place_locales)\n",
    "print(combined_place_locales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73026 34865\n"
     ]
    }
   ],
   "source": [
    "df_t, df_v = util_chips.mask_locales(df, combined_place_locales)\n",
    "print(len(df_t), len(df_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions on selected samples\n",
    "Must be manually adjusted according to whether samples from training & validation locales will be scored independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843/843 [==============================] - 19s 22ms/step\n",
      "(107891, 3)\n"
     ]
    }
   ],
   "source": [
    "generator = CatalogGenerator(df,remapping='3cat',look_window=window,batch_size=batch_size,one_hot=3)\n",
    "generator.reset()\n",
    "\n",
    "#predict_generator(generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "predictions = network.predict_generator(generator, steps=generator.steps, verbose=1,\n",
    "                                        use_multiprocessing=True, max_queue_size=40, workers=64,)\n",
    "\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107891,)\n",
      "(107891,)\n",
      "evaluate validation\n",
      "0 55080\n",
      "1 11915\n",
      "2 40896\n",
      "[[50964  1455  2661]\n",
      " [ 4426  5963  1526]\n",
      " [ 8574  1926 30396]]\n",
      "107891 87323 0.809363153553123\n"
     ]
    }
   ],
   "source": [
    "Yhat = predictions.argmax(axis=-1)\n",
    "Y = generator.get_label_series().values\n",
    "        \n",
    "print(\"evaluate validation\")\n",
    "# hardcoded categories\n",
    "categories=[0,1,2]\n",
    "confusion = util_scoring.calc_confusion(Yhat,Y,categories)\n",
    "recalls, precisions, accuracy = util_scoring.calc_confusion_details(confusion)\n",
    "\n",
    "# Calculate f-score\n",
    "beta = 2\n",
    "f_score = (beta**2 + 1) * precisions * recalls / ( (beta**2 * precisions) + recalls )\n",
    "f_score_open = f_score[0] \n",
    "f_score_nonres = f_score[1]  \n",
    "f_score_res = f_score[2]  \n",
    "f_score_roads = None#f_score[3]  \n",
    "f_score_average = np.mean(f_score)\n",
    "\n",
    "# expanding lists to match expected model_record stuff\n",
    "recalls_expanded = [recalls[0],recalls[1],recalls[2],None]\n",
    "precisions_expanded = [precisions[0],precisions[1],precisions[2],None]\n",
    "\n",
    "# util_scoring.record_model_application(\n",
    "#     model_id, notes, place + '(' + image + ')', label_suffix, resolution, stack_label, feature_count, \n",
    "#     generator.look_window,cats_map, \n",
    "#     confusion, recalls[0], recalls[1], recalls[2], recalls[3], precisions[0], precisions[1], precisions[2], precisions[3], accuracy, \n",
    "#     f_score_open, f_score_nonres, f_score_res, f_score_roads, f_score_average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geoml] *",
   "language": "python",
   "name": "conda-env-geoml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
